{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T09:37:56.265311Z",
     "start_time": "2021-06-03T09:36:56.343739Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T09:37:56.288232Z",
     "start_time": "2021-06-03T09:37:56.279168Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mape(y_true, y_pred):\n",
    "    \n",
    "    '''\n",
    "    Mean Absolute Percentage Error\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    err = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return err\n",
    "\n",
    "def get_rmse(y_true, y_pred):\n",
    "    '''\n",
    "    Root Mean Squared Error\n",
    "    \n",
    "    '''\n",
    "    rmse = (y_true - y_pred)**2\n",
    "    rmse = np.sqrt(np.mean(rmse))\n",
    "    \n",
    "    return rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T13:48:37.484141Z",
     "start_time": "2021-06-03T13:48:37.431150Z"
    }
   },
   "outputs": [],
   "source": [
    "class MmmDataset:\n",
    "    \n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        # load data\n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.set_index('wk_strt_dt')\n",
    "        \n",
    "        # extract impressions and rename\n",
    "        imp_df = df.filter(regex='mdip_.*')\n",
    "        self.impressions_df = imp_df.rename(columns=lambda x: x.replace('mdip_',''))\n",
    "        \n",
    "        # extract spending and rename\n",
    "        spend_df = df.filter(regex='mdsp_.*')\n",
    "        self.spend_df = spend_df.rename(columns=lambda x: x.replace('mdsp_',''))\n",
    "        \n",
    "        # extract base variabiles (macro economics, store counts, markdowns)\n",
    "        self.base_vars_df = df.filter(regex='(me_.*)|(st_ct)|(mrkdn_.*)')\n",
    "        \n",
    "        # extract holidays\n",
    "        self.hldy_df = df.filter(regex='(hldy_.*)')\n",
    "        \n",
    "        # extract seasonals\n",
    "        self.seas_df = df.filter(regex='(seas_.*)')\n",
    "        \n",
    "        # extract target variable\n",
    "        self.target_df = df[['sales']]\n",
    "    \n",
    "        # fitted params placeholders\n",
    "        self.adstock_params = {}\n",
    "        self.hill_params = {}\n",
    "        \n",
    "    def get_base_model_data(self):\n",
    "    \n",
    "        data = {}\n",
    "        \n",
    "        # mean center target\n",
    "        tgt = self.target_df.values.reshape(-1)\n",
    "        data['y_scale'] = tgt.mean()\n",
    "        y = tgt / tgt.mean()\n",
    "        data['y'] = y\n",
    "        data['max_intercept'] = y.min()\n",
    "        \n",
    "        # mean center base vars\n",
    "        centered_base_df = self.base_vars_df / self.base_vars_df.mean(axis=0)\n",
    "        \n",
    "        # variables with positive constrained coefficients\n",
    "        data['positive_vars'] = pd.concat([centered_base_df, self.hldy_df], axis=1).values\n",
    "        data['positive_var_names'] = list(pd.concat([centered_base_df, self.hldy_df], axis=1).columns)\n",
    "        \n",
    "        # variables with non constrained coefficients\n",
    "        data['posneg_vars'] = self.seas_df.values\n",
    "        data['posneg_var_names'] = list(self.seas_df.columns)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def set_baseline_df(self, base_sales):\n",
    "        \n",
    "        self.baseline_df = pd.DataFrame({'baseline_sales' : base_sales})\n",
    "        self.baseline_df.index = self.target_df.index\n",
    "    \n",
    "    def get_mmm_model_data(self):\n",
    "        \n",
    "        \n",
    "        data = {}\n",
    "        \n",
    "        # number of observations\n",
    "        data['N'] = self.impressions_df.shape[0]\n",
    "        \n",
    "        # number of 'base_sales' covariates (ie. equal to one in this case)\n",
    "        data['num_ctrl'] = self.baseline_df.shape[1]\n",
    "        \n",
    "        # mean-log1p-transform of 'base_sales' (ie. predictions from base model)\n",
    "        x = self.baseline_df.values\n",
    "        x = np.log1p(x / x.mean()).reshape(-1,1)\n",
    "        data['x_ctrl'] = x\n",
    "        \n",
    "        #  mean-log1p-transform of the target variable\n",
    "        x = self.target_df.values\n",
    "        x = np.log1p(x / x.mean()).reshape(-1,)\n",
    "        data['y'] = x\n",
    "        \n",
    "        # max lags of adstock filters\n",
    "        data['max_lag'] = 8\n",
    "        \n",
    "        # number of media impressions covariates\n",
    "        data['num_media'] = self.impressions_df.shape[1]\n",
    "        \n",
    "        # means of media impressions\n",
    "        data['mu_mdip'] = self.impressions_df.mean(axis = 0).values\n",
    "        \n",
    "        # media impressions covariates, prepended with zeros of shape (lags-1, # media channels)\n",
    "        x_media = self.impressions_df.values\n",
    "        trailing_zeros = np.zeros((data['max_lag']-1, x_media.shape[1]))\n",
    "        data['x_media'] = np.vstack((trailing_zeros, x_media))\n",
    "        \n",
    "        # media names\n",
    "        data['media_names'] = list(self.impressions_df.columns)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def set_adstock_params(self, mmm_params):\n",
    "        \n",
    "        self.adstock_params.update(mmm_params)\n",
    "    \n",
    "    def set_hill_params(self, hill_params):\n",
    "        \n",
    "        self.hill_params.update(hill_params)\n",
    "        \n",
    "    \n",
    "    def get_adstocked_impressions(self):\n",
    "        \n",
    "        adstock_df = self.impressions_df.copy()\n",
    "        for col in adstock_df.columns:\n",
    "            \n",
    "            x = adstock_df[col].values\n",
    "            l = self.adstock_params[col]['lag']\n",
    "            p = self.adstock_params[col]['peak']\n",
    "            d = self.adstock_params[col]['decay']\n",
    "            adstock_df.loc[:, col] = self._adstock_transform(x, lag=l, peak=p, decay=d)\n",
    "        \n",
    "        return adstock_df\n",
    "    \n",
    "    def get_adstocked_spending(self):\n",
    "        \n",
    "        adstock_df = self.spend_df.copy()\n",
    "        for col in adstock_df.columns:\n",
    "            \n",
    "            x = adstock_df[col].values\n",
    "            l = self.adstock_params[col]['lag']\n",
    "            p = self.adstock_params[col]['peak']\n",
    "            d = self.adstock_params[col]['decay']\n",
    "            adstock_df.loc[:, col] = self._adstock_transform(x, lag=l, peak=p, decay=d)\n",
    "        \n",
    "        return adstock_df\n",
    "    \n",
    "    @classmethod\n",
    "    def _adstock_transform(self, x, lag, peak, decay):\n",
    "    \n",
    "        weights = np.zeros(lag)\n",
    "        for l in range(lag):\n",
    "            weight = decay**((l-peak)**2)\n",
    "            weights[lag-1-l] = weight\n",
    "\n",
    "        # adstock transform\n",
    "        x = np.append(np.zeros(lag-1), x)\n",
    "        adstocked_x = []\n",
    "        for i in range(lag-1, len(x)):\n",
    "            x_array = x[i-lag+1:i+1]\n",
    "            xi = sum(x_array * weights)/sum(weights)\n",
    "            adstocked_x.append(xi)\n",
    "        adstocked_x = np.array(adstocked_x)\n",
    "\n",
    "\n",
    "        return adstocked_x\n",
    "    \n",
    "    def get_media_contribution(self, verbose=False):\n",
    "        \n",
    "        media_names = list(self.impressions_df.columns)\n",
    "        \n",
    "        # mean-center actual sales\n",
    "        y_true = self.target_df.values.reshape(-1)\n",
    "        y_true = y_true / y_true.mean(axis=0)\n",
    "        y_true += 1\n",
    "    \n",
    "        # mean-center base_sales and exponentiate with its beta coefficient\n",
    "        x_base = self.baseline_df.values\n",
    "        x_base = x_base / x_base.mean(axis=0)\n",
    "        x_base += 1\n",
    "        x_base = x_base**self.adstock_params['beta_base']\n",
    "        x_base = x_base.reshape(-1,1)\n",
    "    \n",
    "        # make intercept\n",
    "        intercept = np.exp(self.adstock_params['tau']) * np.ones((y_true.shape[0], 1))\n",
    "    \n",
    "        # calculate baseline sales as x_base * intercept\n",
    "        x = np.hstack([x_base, intercept])\n",
    "        y_baseline = np.prod(x, axis = 1)\n",
    "        \n",
    "    \n",
    "        # mean center adstocked impressions\n",
    "        adstocked = self.get_adstocked_impressions()\n",
    "        adstocked = adstocked / adstocked.mean(axis=0)\n",
    "        adstocked += 1\n",
    "    \n",
    "        # exponentiate matrix of adstocks by beta coefficients\n",
    "        betas = [self.adstock_params[x]['beta'] for x in media_names]\n",
    "        betas = np.array(betas)\n",
    "        x_adstock = adstocked ** betas\n",
    "        \n",
    "    \n",
    "        # calculate predicted sales as product of adstock, base and intercept matrices (ie. multiplicateve product)\n",
    "        x = np.hstack([x_adstock, x_base, intercept])\n",
    "        y_pred = np.prod(x, axis = 1)\n",
    "    \n",
    "        # calculate media contribution of each channel as\n",
    "        # total volume – volume upon removal of the media factor\n",
    "        df = self.impressions_df.copy()\n",
    "        for i, chn in enumerate(media_names):\n",
    "            df[chn] = y_true - (y_true / x_adstock.iloc[:,i])\n",
    "        df['y_baseline'] = y_baseline\n",
    "        df['y_true'] = y_true\n",
    "        \n",
    "        # scale contributions\n",
    "        df['tot_media_contr_true'] = df['y_true'] - df['y_baseline']\n",
    "        df['tot_media_contr_pred'] = df[media_names].apply(np.sum, axis=1)\n",
    "        df['tot_media_contr_delta'] = df['tot_media_contr_pred'] - df['tot_media_contr_true']\n",
    "        \n",
    "        # scale each media contribution by removing the delta volume proportionally\n",
    "        for col in media_names:\n",
    "            df[col] = df[col] - df['tot_media_contr_delta']*df[col]/df['tot_media_contr_pred']\n",
    "        \n",
    "        # scale df based on original sales\n",
    "        for col in media_names+['y_baseline']:\n",
    "            df[col] = df[col]*self.target_df['sales']/df['y_true']\n",
    "        \n",
    "        rmse = get_rmse(y_true=np.log(y_true), y_pred=np.log(y_pred))\n",
    "        mape = get_mape(y_true=y_true, y_pred=y_pred)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'RMSE (log-log model): {rmse}')\n",
    "            print(f'MAPE (multiplicative model): {mape}')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_chn_percent_contrib(self, period=52):\n",
    "        '''\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        \n",
    "        perc_contr : percentage contribution to total sales\n",
    "        perc_contr_incr : percentage contribution to incremental sales (ie. sales generated by media channels only)\n",
    "        \n",
    "        '''\n",
    "        # get media contributions\n",
    "        df = self.get_media_contribution()\n",
    "        \n",
    "        # get list of media names\n",
    "        media_channels = list(self.impressions_df.columns)\n",
    "\n",
    "        # subset columns\n",
    "        df = df[media_channels + ['y_baseline']]\n",
    "        \n",
    "        y_true = self.target_df['sales'].values\n",
    "        # subset to period\n",
    "        if period:\n",
    "            df = df.tail(period)\n",
    "            y_true = y_true[-period:]\n",
    "            \n",
    "        # calculate percentage contribution of each channel to total sales\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col] / y_true\n",
    "        perc_contr = df.mean()\n",
    "\n",
    "        # calculate percentage contribution of each channel to incremental sales\n",
    "        # ie. sales contributed by media channels excl. baseline\n",
    "        perc_contr_incr = perc_contr.drop('y_baseline')\n",
    "        perc_contr_incr = perc_contr_incr / perc_contr_incr.sum()\n",
    "\n",
    "        return perc_contr, perc_contr_incr\n",
    "    \n",
    "    def get_hill_model_data(self):\n",
    "        \n",
    "        # get media contributions and center\n",
    "        df_contr = self.get_media_contribution()\n",
    "        df_contr = df_contr / df_contr.mean()\n",
    "        df_contr = df_contr.reset_index()\n",
    "        df_contr = df_contr.melt(id_vars = 'wk_strt_dt',\n",
    "                                 var_name='media_channel',\n",
    "                                 value_name='media_contrib')\n",
    "\n",
    "        # get adstocked media spend and center\n",
    "        adstocked_spend = self.get_adstocked_spending()\n",
    "        adstocked_spend = adstocked_spend / adstocked_spend.mean()\n",
    "        adstocked_spend = adstocked_spend.reset_index()\n",
    "        adstocked_spend = adstocked_spend.melt(id_vars = 'wk_strt_dt',\n",
    "                                               var_name='media_channel',\n",
    "                                               value_name='adstock_spend')\n",
    "        \n",
    "        # merge\n",
    "        df = df_contr.merge(adstocked_spend, on = ['wk_strt_dt', 'media_channel'])\n",
    "        \n",
    "        # drop zeros\n",
    "        df = df[(df['adstock_spend'] > 0) & (df['media_contrib'] > 0)]\n",
    "        \n",
    "        # extract channel indices and names\n",
    "        media_index, media_channels = pd.factorize(df['media_channel'])\n",
    "        \n",
    "        # create data dict\n",
    "        data = {}\n",
    "        data['y'] = df['media_contrib'].values\n",
    "        data['x'] = df['adstock_spend'].values\n",
    "        data['channel_index'] = media_index\n",
    "        data['channel_names'] = list(media_channels)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_roas(self, period=52, plot=True):\n",
    "        \n",
    "        contr_df = self.get_media_contribution()\n",
    "        spend_df = self.get_adstocked_spending()\n",
    "        \n",
    "        cols = set.intersection(set(contr_df.columns), set(spend_df.columns))\n",
    "\n",
    "        contr_df = contr_df[cols]\n",
    "        spend_df = spend_df[cols]\n",
    "\n",
    "        if period:\n",
    "            contr_df = contr_df.tail(period)\n",
    "            spend_df = spend_df.tail(period)\n",
    "\n",
    "        df = contr_df / spend_df\n",
    "\n",
    "        agg_df = df.agg(['mean', 'median']).T\n",
    "\n",
    "        sums_df = contr_df.sum() / spend_df.sum()\n",
    "        agg_df['sum'] = sums_df\n",
    "\n",
    "        agg_df = agg_df.rename(columns={\n",
    "            'mean': 'roas_mean',\n",
    "            'median': 'roas_median',\n",
    "            'sum': 'roas_avg',\n",
    "        })\n",
    "\n",
    "        if plot:\n",
    "            df = df.melt(var_name='channel', value_name='weekly_roas')\n",
    "            g = sns.FacetGrid(col='channel', col_wrap=5, data = df, sharey=False, sharex=False)\n",
    "            g.map(sns.histplot, 'weekly_roas', kde = True, stat='density');\n",
    "\n",
    "\n",
    "            for mn, md, ax in zip(agg_df['roas_mean'].values, agg_df['roas_median'].values, g.axes.ravel()):\n",
    "                ax.vlines(mn, *ax.get_ylim(), color='g')\n",
    "                ax.vlines(md, *ax.get_ylim(), color='r')\n",
    "    \n",
    "    \n",
    "        mroas_dict = {}\n",
    "        for chn in list(agg_df.index):\n",
    "            \n",
    "            x = self.get_adstocked_spending()[chn].tail(period)\n",
    "            x_scale = self.get_adstocked_spending()[chn].mean()\n",
    "            beta = self.hill_params[chn]['beta']\n",
    "            slope = self.hill_params[chn]['slope']\n",
    "            ec = self.hill_params[chn]['ec']\n",
    "            y_scale = self.get_media_contribution()[chn].mean()\n",
    "            \n",
    "            mroas = self._calc_mroas(x, x_scale, beta, slope, ec, y_scale)\n",
    "            \n",
    "            mroas_dict[chn] = mroas\n",
    "        \n",
    "        agg_df['mroas'] = pd.Series(mroas_dict)\n",
    "        \n",
    "        return agg_df\n",
    "    \n",
    "    def _calc_mroas(self, x, x_scale, beta, slope, ec, y_scale, marginal_increase = .01):\n",
    "        \n",
    "\n",
    "        # mean center x\n",
    "        current_x = x / x_scale\n",
    "\n",
    "        # predict contribution using hill transformation\n",
    "        current_y = beta * (1 / (1 + (current_x / ec)**(-slope)))\n",
    "        current_y = current_y * y_scale\n",
    "\n",
    "        # predict contribution after marginal increase\n",
    "        next_x = current_x * (1+marginal_increase)\n",
    "        next_y = beta * (1 / (1 + (next_x / ec)**(-slope)))\n",
    "        next_y = next_y * y_scale\n",
    "\n",
    "        # calc mROAS\n",
    "        delta_y = next_y.sum() - current_y.sum()\n",
    "        delta_x = (next_x * x_scale).sum() - (current_x * x_scale).sum()\n",
    "        mroas = delta_y/delta_x\n",
    "\n",
    "        return mroas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PymcBaseModel:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # save data\n",
    "        self.data = data\n",
    "        \n",
    "        # define model\n",
    "        with pm.Model() as self.model:\n",
    "\n",
    "            # priors\n",
    "            beta1 = pm.HalfNormal('beta1', sigma=1, shape = self.data['positive_vars'].shape[1])\n",
    "            beta2 = pm.Normal('beta2', mu = 0, sigma=1, shape = self.data['posneg_vars'].shape[1])\n",
    "            alpha = pm.Uniform('alpha', lower = 0, upper = self.data['max_intercept'])\n",
    "            sigma = pm.InverseGamma('noise_var', alpha=0.05, beta=0.05 * 0.01)\n",
    "\n",
    "            # linear regression\n",
    "            mu = tt.dot(self.data['positive_vars'], beta1) + tt.dot(self.data['posneg_vars'], beta2) + alpha\n",
    "\n",
    "            # likelihood\n",
    "            y = pm.Normal('y_obs', mu=mu, sigma=sigma**.5, observed=self.data['y'])\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        with self.model:\n",
    "            # fit posterior and predict \n",
    "            self.trace = pm.sample(draws=2000, chains=4, return_inferencedata=False)\n",
    "            self.posterior_predictive = pm.sample_posterior_predictive(self.trace)\n",
    "            \n",
    "    def get_regression_coefficients(self):\n",
    "        \n",
    "        # display regression coefficients with arviz\n",
    "        results = az.from_pymc3(\n",
    "            trace=self.trace,\n",
    "            model=self.model,\n",
    "            posterior_predictive=self.posterior_predictive,\n",
    "            dims={\n",
    "                'beta1': ['b1'],\n",
    "                'beta2': ['b2'],\n",
    "                    },\n",
    "            coords={\n",
    "                'b1': self.data['positive_var_names'],\n",
    "                'b2': self.data['posneg_var_names'],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        posterior_df = az.summary(results, var_names=['beta1', 'beta2', 'alpha'])\n",
    "        posterior_df.index = self.data['positive_var_names'] + self.data['posneg_var_names'] + ['max_intercept']\n",
    "        return posterior_df\n",
    "\n",
    "    def get_baseline_sales(self):\n",
    "        \n",
    "        # save baseline sales into dataset (baseline must be rescaled)\n",
    "        baseline = self.posterior_predictive['y_obs'].mean(axis = 0) \n",
    "        baseline *= self.data['y_scale']\n",
    "        \n",
    "        return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PystanMmmModel:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.data = data\n",
    "        self.media_names = self.data['media_names']\n",
    "        self.data.pop('media_names', None)\n",
    "        \n",
    "        model_specs = '''\n",
    "                        functions {\n",
    "                          // the adstock transformation with a vector of weights\n",
    "                          real Adstock(vector t, row_vector weights) {\n",
    "                            return dot_product(t, weights) / sum(weights);\n",
    "                          }\n",
    "                        }\n",
    "                        data {\n",
    "                          // the total number of observations\n",
    "                          int<lower=1> N;\n",
    "\n",
    "                          // the vector of sales\n",
    "                          real y[N];\n",
    "\n",
    "                          // the maximum duration of lag effect, in weeks\n",
    "                          int<lower=1> max_lag;\n",
    "\n",
    "                          // the number of media channels\n",
    "                          int<lower=1> num_media;\n",
    "\n",
    "                          // matrix of media variables\n",
    "                          matrix[N+max_lag-1, num_media] x_media;\n",
    "\n",
    "                          // vector of media variables' mean\n",
    "                          real mu_mdip[num_media];\n",
    "\n",
    "                          // the number of other control variables\n",
    "                          int<lower=1> num_ctrl;\n",
    "\n",
    "                          // a matrix of control variables\n",
    "                          matrix[N, num_ctrl] x_ctrl;\n",
    "                        }\n",
    "\n",
    "                        parameters {\n",
    "\n",
    "                          // residual variance\n",
    "                          real<lower=0> noise_var;\n",
    "\n",
    "                          // the intercept\n",
    "                          real tau;\n",
    "\n",
    "                          // the coefficients for media variables and base sales\n",
    "                          vector<lower=0>[num_media+num_ctrl] beta;\n",
    "\n",
    "                          // the decay and peak parameter for the adstock transformation of\n",
    "                          // each media\n",
    "                          vector<lower=0,upper=1>[num_media] decay;\n",
    "                          vector<lower=0,upper=ceil(max_lag/2)>[num_media] peak;\n",
    "\n",
    "                        }\n",
    "\n",
    "                        transformed parameters {\n",
    "                          // the cumulative media effect after adstock\n",
    "                          real cum_effect;\n",
    "\n",
    "                          // matrix of media variables after adstock\n",
    "                          matrix[N, num_media] X_media_adstocked;\n",
    "\n",
    "                          // matrix of all predictors\n",
    "                          matrix[N, num_media+num_ctrl] X;\n",
    "\n",
    "                          // adstock, mean-center, log1p transformation\n",
    "                          row_vector[max_lag] lag_weights;\n",
    "                          for (nn in 1:N) {\n",
    "                            for (media in 1 : num_media) {\n",
    "                              for (lag in 1 : max_lag) {\n",
    "                                lag_weights[max_lag-lag+1] <- pow(decay[media], (lag - 1 - peak[media]) ^ 2);\n",
    "                              }\n",
    "                             cum_effect <- Adstock(sub_col(x_media, nn, media, max_lag), lag_weights);\n",
    "                             X_media_adstocked[nn, media] <- log1p(cum_effect/mu_mdip[media]);\n",
    "                            }\n",
    "                          X <- append_col(X_media_adstocked, x_ctrl);\n",
    "                          } \n",
    "                        }\n",
    "                        model {\n",
    "                          decay ~ beta(3,3);\n",
    "                          peak ~ uniform(0, ceil(max_lag/2));\n",
    "                          tau ~ normal(0, 5);\n",
    "                          for (i in 1 : num_media+num_ctrl) {\n",
    "                            beta[i] ~ normal(0, 1);\n",
    "                          }\n",
    "                          noise_var ~ inv_gamma(0.05, 0.05 * 0.01);\n",
    "                          y ~ normal(tau + X * beta, sqrt(noise_var));\n",
    "                        }\n",
    "                        '''\n",
    "        \n",
    "        # elapsed appx 45 minutes\n",
    "        self.model = pystan.StanModel(model_code=model_specs, verbose=True)\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        fitted_model = self.model.sampling(data=self.data, iter=1000, chains=3)\n",
    "        self.fitted_results = fitted_model.extract()\n",
    "    \n",
    "    def get_results(self):\n",
    "    \n",
    "        data = {}\n",
    "        \n",
    "        media_vars = self.media_names\n",
    "        \n",
    "        # extract regression coefficients (betas) and adstock params for each media channel\n",
    "        for i, media in enumerate(media_vars):\n",
    "\n",
    "            data[media] = {}\n",
    "\n",
    "            # regression coefficient\n",
    "            data[media]['beta'] = self.fitted_results['beta'][:,i].mean()\n",
    "\n",
    "            # adstock params\n",
    "            data[media]['peak'] = self.fitted_results['peak'][:,i].mean()\n",
    "            data[media]['decay'] = self.fitted_results['decay'][:,i].mean()\n",
    "            data[media]['lag'] = self.data['max_lag']\n",
    "\n",
    "        # extract regression coefficient for base model covariate (ie.'base_sales') correspondent to last beta\n",
    "        data['beta_base'] = self.fitted_results['beta'][:,-1].mean()\n",
    "\n",
    "        # extract tau\n",
    "        data['tau'] = self.fitted_results['tau'].mean()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def plot_betas(self):\n",
    "        \n",
    "        plot_df = pd.DataFrame(self.fitted_results['beta'][:,:-1], columns=self.media_names).melt()\n",
    "        g = sns.FacetGrid(col='variable', col_wrap=5, data = plot_df, sharey=False, sharex=False)\n",
    "        g.map(sns.histplot, 'value', kde = True);\n",
    "        \n",
    "        means = plot_df.groupby('variable')['value'].mean()\n",
    "        medians = plot_df.groupby('variable')['value'].median()\n",
    "        \n",
    "        for mn, md, ax in zip(means, medians, g.axes.ravel()):\n",
    "            ax.vlines(mn, *ax.get_ylim(), color='g')\n",
    "            ax.vlines(md, *ax.get_ylim(), color='r')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PymcHillModel:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # save data\n",
    "        self.data = data\n",
    "        \n",
    "        # shape\n",
    "        shape = len(data['channel_names'])\n",
    "        \n",
    "        # define model\n",
    "        with pm.Model() as self.model:\n",
    "\n",
    "            # priors\n",
    "            slope     = pm.Gamma('slope', alpha=3, beta=1, shape = shape)\n",
    "            ec        = pm.Beta('ec', alpha=2, beta=2, shape = shape)\n",
    "            beta      = pm.Normal('beta', mu=0, sigma=1, shape = shape)\n",
    "            noise_var = pm.InverseGamma('noise_var', alpha=0.05, beta=0.05 * 0.01, shape = shape)\n",
    "\n",
    "            # hill transform\n",
    "            beta_chn = beta[data['channel_index']]\n",
    "            slope_chn = slope[data['channel_index']]\n",
    "            ec_chn = ec[data['channel_index']]\n",
    "            mu = beta_chn * (1 / (1 + (data['x'] / ec_chn)**(-slope_chn)))\n",
    "            \n",
    "            # likelihood\n",
    "            noise_var_chn = noise_var[data['channel_index']]\n",
    "            y = pm.Normal('y_obs', mu=mu, sigma=noise_var_chn**.5, observed=self.data['y'])\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        with self.model:\n",
    "            # fit posteriors\n",
    "            self.trace = pm.sample(draws=2000, chains=4, return_inferencedata=False)\n",
    "        \n",
    "        self.hill_coefficients = self._set_hill_coefficients()\n",
    "            \n",
    "    def _set_hill_coefficients(self):\n",
    "        \n",
    "        # convert to arviz\n",
    "        results = az.from_pymc3(trace=self.trace, model=self.model)\n",
    "\n",
    "        # convert to dataframe\n",
    "        results_df = az.summary(results)[['mean']].values\n",
    "        results_df = results_df.reshape(len(self.data['channel_names']),-1, order='F')\n",
    "        results_df = pd.DataFrame(results_df,\n",
    "                                  index=self.data['channel_names'],\n",
    "                                  columns=['beta', 'slope', 'ec', 'noise_var'])\n",
    "        # take to dict\n",
    "        res = {}\n",
    "        for k in self.data['channel_names']:\n",
    "            res[k] = dict(results_df.loc[k])\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def get_hill_coefficients(self):\n",
    "        \n",
    "        return self.hill_coefficients\n",
    "    \n",
    "    def plot_predictions(self):\n",
    "        df = pd.DataFrame({\n",
    "            'x' : self.data['x'],\n",
    "            'y' : self.data['y'],\n",
    "            'channel' : pd.Series(self.data['channel_index']).map(lambda x: self.data['channel_names'][x])\n",
    "        })\n",
    "        \n",
    "        df['beta'] = df['channel'].map(lambda x: self.hill_coefficients[x]['beta'])\n",
    "        df['ec'] = df['channel'].map(lambda x: self.hill_coefficients[x]['ec'])\n",
    "        df['slope'] = df['channel'].map(lambda x: self.hill_coefficients[x]['slope'])\n",
    "        df['prediction'] = df.apply(lambda x: x['beta'] * (1 / (1 + (x['x'] / x['ec'])**(-x['slope']))), axis = 1)\n",
    "        \n",
    "        g = sns.FacetGrid(col='channel', col_wrap=5, data = df, sharey=False, sharex=False)\n",
    "        g.map(sns.scatterplot, 'x', 'y', alpha = .1);\n",
    "        g.map(sns.lineplot, 'x', 'prediction', color='red');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
